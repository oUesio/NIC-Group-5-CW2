{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ded353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading TTP instanceâ€¦\n",
      "[INFO] Building NN tourâ€¦\n",
      "[TSP] NN length = 3176\n",
      "[INFO] Building candidate lists with k=279 using sklearn...\n",
      "[INFO] Running 2-opt with candidate listsâ€¦\n",
      "[2-OPT] Pass 50  |  Best length so far = 2833\n",
      "[2-OPT] Early stop at pass 52, no improvement.\n",
      "[TSP] Improved length = 2823\n",
      "[INFO] Preprocessing itemsâ€¦\n",
      "[GEN    0] min_time=2829.2  max_profit=40613\n",
      "[GEN    1] min_time=2829.2  max_profit=40613\n",
      "[GEN    2] min_time=2829.2  max_profit=40613\n",
      "[GEN    3] min_time=2829.2  max_profit=40613\n",
      "[GEN    4] min_time=2829.2  max_profit=40613\n",
      "[GEN    5] min_time=2829.2  max_profit=40613\n",
      "[GEN    6] min_time=2829.2  max_profit=40613\n",
      "[GEN    7] min_time=2829.2  max_profit=40613\n",
      "[GEN    8] min_time=2829.2  max_profit=40613\n",
      "[GEN    9] min_time=2829.2  max_profit=40613\n",
      "[GEN   10] min_time=2829.2  max_profit=40613\n",
      "[GEN   11] min_time=2829.2  max_profit=40613\n",
      "[GEN   12] min_time=2829.2  max_profit=40613\n",
      "[GEN   13] min_time=2829.2  max_profit=40613\n",
      "[GEN   14] min_time=2829.2  max_profit=40613\n",
      "[GEN   15] min_time=2829.2  max_profit=40613\n",
      "[GEN   16] min_time=2829.2  max_profit=40613\n",
      "[GEN   17] min_time=2829.2  max_profit=40613\n",
      "[GEN   18] min_time=2829.2  max_profit=40613\n",
      "[GEN   19] min_time=2829.2  max_profit=40613\n",
      "[GEN   20] min_time=2829.2  max_profit=40613\n",
      "[GEN   21] min_time=2829.2  max_profit=40613\n",
      "[GEN   22] min_time=2829.2  max_profit=40613\n",
      "[GEN   23] min_time=2829.2  max_profit=40613\n",
      "[GEN   24] min_time=2829.2  max_profit=40613\n",
      "[GEN   25] min_time=2829.2  max_profit=40613\n",
      "[GEN   26] min_time=2829.2  max_profit=40613\n",
      "[GEN   27] min_time=2829.2  max_profit=40613\n",
      "[GEN   28] min_time=2829.2  max_profit=40613\n",
      "[GEN   29] min_time=2829.2  max_profit=40613\n",
      "[GEN   30] min_time=2829.2  max_profit=40984\n",
      "[GEN   31] min_time=2829.2  max_profit=40984\n",
      "[GEN   32] min_time=2829.2  max_profit=40984\n",
      "[GEN   33] min_time=2829.2  max_profit=40984\n",
      "[GEN   34] min_time=2829.2  max_profit=40984\n",
      "[GEN   35] min_time=2829.2  max_profit=41140\n",
      "[GEN   36] min_time=2829.2  max_profit=41140\n",
      "[GEN   37] min_time=2829.2  max_profit=41140\n",
      "[GEN   38] min_time=2829.2  max_profit=41140\n",
      "[GEN   39] min_time=2829.2  max_profit=41140\n",
      "[GEN   40] min_time=2829.2  max_profit=41140\n",
      "[GEN   41] min_time=2829.2  max_profit=41140\n",
      "[GEN   42] min_time=2829.2  max_profit=41140\n",
      "[GEN   43] min_time=2829.2  max_profit=41140\n",
      "[GEN   44] min_time=2829.2  max_profit=41140\n",
      "[GEN   45] min_time=2829.2  max_profit=41140\n",
      "[GEN   46] min_time=2829.2  max_profit=41140\n",
      "[GEN   47] min_time=2829.2  max_profit=41140\n",
      "[GEN   48] min_time=2829.2  max_profit=41140\n",
      "[GEN   49] min_time=2829.2  max_profit=41140\n",
      "[GEN   50] min_time=2829.2  max_profit=41140\n",
      "[GEN   51] min_time=2829.2  max_profit=41140\n",
      "[GEN   52] min_time=2829.2  max_profit=41140\n",
      "[GEN   53] min_time=2829.2  max_profit=41140\n",
      "[GEN   54] min_time=2829.2  max_profit=41140\n",
      "[GEN   55] min_time=2829.2  max_profit=41140\n",
      "[GEN   56] min_time=2829.2  max_profit=41140\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# ============================\n",
    "# GLOBAL CONFIG\n",
    "# ============================\n",
    "\n",
    "INSTANCE_PATH = r\"gecco19-thief\\src\\main\\resources\\a280-n279.txt\"\n",
    "\n",
    "# TSP / 2-OPT\n",
    "CAND_K = 279\n",
    "TWO_OPT_PASSES = 2000\n",
    "\n",
    "# EVOLUTION\n",
    "POP_SIZE = 600\n",
    "GENERATIONS = 2000\n",
    "TOURN_K = 3\n",
    "\n",
    "NUM_GREEDIES = 200      # tune to 2-8 depending runtime\n",
    "\n",
    "HC_STEPS = 1000  # tune later\n",
    "TOUR_2OPT_STEPS = 279  # keep small or you'll regret it\n",
    "\n",
    "# ITEM SEEDING PARAMETERS\n",
    "CAP_FACTORS = [0.03, 0.05, 0.075, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.7, 0.9, 1.0]\n",
    "GAMMAS = [0, 0.25, 0.5, 0.75, 1, 1.5, 2, 3, 4, 6, 8, 10, 15, 20, 30]\n",
    "HEUR_MODES = [\"suffix\", \"profit_adj\", \"time_ratio\"]\n",
    "MUT_RATE = 0.003\n",
    "LIGHT_MUT_RATE = 0.02\n",
    "\n",
    "GLOBAL_SEED = 0\n",
    "random.seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "\n",
    "# HYPERVOLUME (same reference used in your comparisons)\n",
    "IDEAL = (2613.0, -42036.0)\n",
    "NADIR = (5444.0, 0.0)\n",
    "\n",
    "MAX_ARCHIVE = 100          # same behaviour as second file (cap via crowding)\n",
    "archive_pop = []          # stores solutions\n",
    "archive_objs = []         # stores (T,P,W)\n",
    "\n",
    "# Global elites across all generations\n",
    "bestP = -1.0\n",
    "bestP_sol = None\n",
    "\n",
    "bestT = None\n",
    "bestT_sol = None\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# PARSE INSTANCE\n",
    "# ===============================================================\n",
    "def parse_ttp(path: str) -> Dict[str, Any]:\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    dim = num_items = None\n",
    "    capacity = v_min = v_max = None\n",
    "    edge_type = None\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        L = lines[i]\n",
    "        if L.startswith(\"DIMENSION\"):\n",
    "            dim = int(L.split(\":\")[1])\n",
    "        elif L.startswith(\"NUMBER OF ITEMS\"):\n",
    "            num_items = int(L.split(\":\")[1])\n",
    "        elif L.startswith(\"CAPACITY OF KNAPSACK\"):\n",
    "            capacity = float(L.split(\":\")[1])\n",
    "        elif L.startswith(\"MIN SPEED\"):\n",
    "            v_min = float(L.split(\":\")[1])\n",
    "        elif L.startswith(\"MAX SPEED\"):\n",
    "            v_max = float(L.split(\":\")[1])\n",
    "        elif L.startswith(\"EDGE_WEIGHT_TYPE\"):\n",
    "            edge_type = L.split(\":\")[1].strip()\n",
    "        elif L.startswith(\"NODE_COORD_SECTION\"):\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    i += 1\n",
    "    coords = np.zeros((dim, 2), float)\n",
    "    for k in range(dim):\n",
    "        idx, x, y = lines[i + k].split()\n",
    "        coords[int(idx) - 1] = [float(x), float(y)]\n",
    "    i += dim\n",
    "\n",
    "    while \"ITEMS SECTION\" not in lines[i]:\n",
    "        i += 1\n",
    "    i += 1\n",
    "\n",
    "    items = []\n",
    "    for j in range(num_items):\n",
    "        parts = lines[i + j].split()\n",
    "        profit = float(parts[1])\n",
    "        weight = float(parts[2])\n",
    "        city = int(parts[3]) - 1\n",
    "        items.append((profit, weight, city))\n",
    "\n",
    "    return {\n",
    "        \"dim\": dim,\n",
    "        \"coords\": coords,\n",
    "        \"items\": items,\n",
    "        \"capacity\": capacity,\n",
    "        \"v_min\": v_min,\n",
    "        \"v_max\": v_max,\n",
    "        \"edge_type\": edge_type,\n",
    "    }\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# TSP (Nearest Neighbour + 2-opt with candidate lists)\n",
    "# ===============================================================\n",
    "def nn_tour(coords: np.ndarray) -> np.ndarray:\n",
    "    n = len(coords)\n",
    "    unvis = np.ones(n, dtype=bool)\n",
    "    tour = np.empty(n, int)\n",
    "    cur = 0\n",
    "\n",
    "    for t in range(n):\n",
    "        tour[t] = cur\n",
    "        unvis[cur] = False\n",
    "        if t == n - 1:\n",
    "            break\n",
    "        dx = coords[unvis, 0] - coords[cur, 0]\n",
    "        dy = coords[unvis, 1] - coords[cur, 1]\n",
    "        nxt = np.where(unvis)[0][np.argmin(dx * dx + dy * dy)]\n",
    "        cur = nxt\n",
    "\n",
    "    return tour\n",
    "\n",
    "\n",
    "def compute_dists(order: np.ndarray, coords: np.ndarray) -> np.ndarray:\n",
    "    n = len(order)\n",
    "    out = np.empty(n, float)\n",
    "    for i in range(n):\n",
    "        a = order[i]\n",
    "        b = order[(i + 1) % n]\n",
    "        d = math.sqrt(((coords[a] - coords[b]) ** 2).sum())\n",
    "        out[i] = math.ceil(d)\n",
    "    return out\n",
    "\n",
    "\n",
    "def city_dist(a: int, b: int, coords: np.ndarray) -> float:\n",
    "    dx = coords[a, 0] - coords[b, 0]\n",
    "    dy = coords[a, 1] - coords[b, 1]\n",
    "    return math.ceil(math.hypot(dx, dy))\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# PURE PYTHON KNN \n",
    "# -------------------------------------------\n",
    "from pure_knn import build_knn_lists\n",
    "\n",
    "def build_candidate_lists(coords: np.ndarray, k=CAND_K):\n",
    "    print(f\"[INFO] Building candidate lists WITHOUT sklearn, k={k} ...\")\n",
    "    return build_knn_lists(coords, k)\n",
    "\n",
    "\n",
    "def two_opt_with_candidates(order: np.ndarray,\n",
    "                            coords: np.ndarray,\n",
    "                            cand_lists,\n",
    "                            max_passes=TWO_OPT_PASSES) -> np.ndarray:\n",
    "\n",
    "    if cand_lists is None:\n",
    "        return order\n",
    "\n",
    "    n = len(order)\n",
    "    pos = np.empty(n, int)\n",
    "    for idx, city in enumerate(order):\n",
    "        pos[city] = idx\n",
    "\n",
    "    # track best found so far for print purposes ONLY\n",
    "    best_len = sum(city_dist(order[i], order[(i+1)%n], coords) for i in range(n))\n",
    "\n",
    "    for p in range(max_passes):\n",
    "        improved = False\n",
    "\n",
    "        for i in range(n - 1):\n",
    "            a = order[i]\n",
    "            b = order[i + 1]\n",
    "\n",
    "            for c in cand_lists[a]:\n",
    "                j = pos[c]\n",
    "                if j <= i + 1 or j >= n - 1:\n",
    "                    continue\n",
    "\n",
    "                d = order[j + 1]\n",
    "\n",
    "                old_len = city_dist(a, b, coords) + city_dist(c, d, coords)\n",
    "                new_len = city_dist(a, c, coords) + city_dist(b, d, coords)\n",
    "\n",
    "                if new_len < old_len:\n",
    "                    order[i+1:j+1] = order[i+1:j+1][::-1]\n",
    "\n",
    "                    for t in range(i+1, j+1):\n",
    "                        pos[order[t]] = t\n",
    "\n",
    "                    improved = True\n",
    "                    curr_len = sum(city_dist(order[k], order[(k+1)%n], coords) for k in range(n))\n",
    "                    best_len = min(best_len, curr_len)\n",
    "                    break\n",
    "\n",
    "            if improved:\n",
    "                break\n",
    "\n",
    "        if not improved:\n",
    "            print(f\"[2-OPT] Early stop at pass {p+1}, no improvement.\")\n",
    "            break\n",
    "\n",
    "        # print every 50 iterations\n",
    "        if (p+1) % 50 == 0:\n",
    "            print(f\"[2-OPT] Pass {p+1}  |  Best length so far = {best_len}\")\n",
    "\n",
    "    return order\n",
    "\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# PRECOMPUTE ITEM DATA\n",
    "# ===============================================================\n",
    "def prep_items(inst, order, dists):\n",
    "    n = inst[\"dim\"]\n",
    "    city_pos = np.empty(n, int)\n",
    "    for pos, city in enumerate(order):\n",
    "        city_pos[city] = pos\n",
    "\n",
    "    suffix = np.empty(len(dists))\n",
    "    run = 0.0\n",
    "    for i in reversed(range(len(dists))):\n",
    "        run += dists[i]\n",
    "        suffix[i] = run\n",
    "\n",
    "    recs = []\n",
    "    for idx, (p, w, c) in enumerate(inst[\"items\"]):\n",
    "        pos = city_pos[c]\n",
    "        recs.append({\n",
    "            \"index\": idx,\n",
    "            \"city\": c,\n",
    "            \"pos\": pos,\n",
    "            \"profit\": p,\n",
    "            \"weight\": w,\n",
    "            \"suffix\": float(suffix[pos])\n",
    "        })\n",
    "\n",
    "    return recs, float(suffix[0])\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# EVALUATION\n",
    "# ===============================================================\n",
    "def evaluate(inst, order, dists, recs, chosen):\n",
    "    cap = inst[\"capacity\"]\n",
    "    vmin = inst[\"v_min\"]\n",
    "    vmax = inst[\"v_max\"]\n",
    "\n",
    "    city_w = np.zeros(len(order), float)\n",
    "    city_p = np.zeros(len(order), float)\n",
    "\n",
    "    for r, ch in zip(recs, chosen):\n",
    "        if ch:\n",
    "            city_w[r[\"pos\"]] += r[\"weight\"]\n",
    "            city_p[r[\"pos\"]] += r[\"profit\"]\n",
    "\n",
    "    alpha = (vmax - vmin) / cap\n",
    "\n",
    "    W = 0.0\n",
    "    T = 0.0\n",
    "    P = 0.0\n",
    "\n",
    "    for i in range(len(order)):\n",
    "        W += city_w[i]\n",
    "        v = vmax - alpha * W\n",
    "        if v < vmin:\n",
    "            v = vmin\n",
    "        T += dists[i] / v\n",
    "        P += city_p[i]\n",
    "\n",
    "    return T, P, W\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# CAPACITY REPAIR\n",
    "# ===============================================================\n",
    "def repair_to_capacity(chosen, recs, capacity):\n",
    "    \"\"\"\n",
    "    Ensure total weight <= capacity by dropping worst profit/weight items.\n",
    "    \"\"\"\n",
    "    weights = np.array([r[\"weight\"] for r in recs], dtype=float)\n",
    "    profits = np.array([r[\"profit\"] for r in recs], dtype=float)\n",
    "\n",
    "    chosen = list(chosen)\n",
    "    total_w = float((weights * np.array(chosen, dtype=float)).sum())\n",
    "\n",
    "    if total_w <= capacity:\n",
    "        return chosen\n",
    "\n",
    "    chosen_idx = [i for i, flag in enumerate(chosen) if flag]\n",
    "    chosen_idx.sort(key=lambda i: profits[i] / weights[i])  # worst first\n",
    "\n",
    "    for i in chosen_idx:\n",
    "        if total_w <= capacity:\n",
    "            break\n",
    "        chosen[i] = False\n",
    "        total_w -= weights[i]\n",
    "\n",
    "    return chosen\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# GREEDY SEEDING MODES\n",
    "# ===============================================================\n",
    "\n",
    "def build_seed(inst, order, dists, recs, total_dist):\n",
    "    mode = random.choice(HEUR_MODES)\n",
    "    gamma = random.choice(GAMMAS)\n",
    "    power = random.choice([0.5, 1.0, 2.0])\n",
    "    cap_target = random.choice(CAP_FACTORS) * inst[\"capacity\"]\n",
    "\n",
    "    if mode == \"suffix\":\n",
    "        for r in recs:\n",
    "            r[\"score\"] = (r[\"suffix\"] / total_dist) ** power\n",
    "\n",
    "    elif mode == \"profit_adj\":\n",
    "        for r in recs:\n",
    "            adj = r[\"weight\"] * (1.0 + gamma * (r[\"suffix\"] / total_dist))\n",
    "            r[\"score\"] = r[\"profit\"] / adj\n",
    "\n",
    "    else:\n",
    "        alpha = (inst[\"v_max\"] - inst[\"v_min\"]) / inst[\"capacity\"]\n",
    "        for r in recs:\n",
    "            dv = alpha * r[\"weight\"]\n",
    "            v_before = inst[\"v_max\"]\n",
    "            v_after = max(inst[\"v_max\"] - dv, inst[\"v_min\"])\n",
    "            dt = r[\"suffix\"] / v_after - r[\"suffix\"] / v_before\n",
    "            if dt <= 0:\n",
    "                dt = 1e-6\n",
    "            r[\"score\"] = r[\"profit\"] / dt\n",
    "\n",
    "    idxs = sorted(range(len(recs)), key=lambda i: recs[i][\"score\"], reverse=True)\n",
    "\n",
    "    chosen = [False] * len(recs)\n",
    "    W = 0.0\n",
    "    for i in idxs:\n",
    "        w = recs[i][\"weight\"]\n",
    "        if W + w <= cap_target:\n",
    "            chosen[i] = True\n",
    "            W += w\n",
    "\n",
    "    chosen = repair_to_capacity(chosen, recs, inst[\"capacity\"])\n",
    "    return chosen\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# MUTATION / CROSSOVER\n",
    "# ===============================================================\n",
    "def mutate(chosen, rate=MUT_RATE):\n",
    "    out = chosen[:]\n",
    "    for i in range(len(out)):\n",
    "        if random.random() < rate:\n",
    "            out[i] = not out[i]\n",
    "    return out\n",
    "\n",
    "\n",
    "def light_mutate(chosen, rate=LIGHT_MUT_RATE):\n",
    "    out = chosen[:]\n",
    "    for i in range(len(out)):\n",
    "        if random.random() < rate:\n",
    "            out[i] = not out[i]\n",
    "    return out\n",
    "\n",
    "\n",
    "def crossover(a, b):\n",
    "    n = len(a)\n",
    "    cut = random.randint(0, n - 1)\n",
    "    return a[:cut] + b[cut:]\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# NSGA-II\n",
    "# ===============================================================\n",
    "def dominates(A, B):\n",
    "    t1, p1, _ = A\n",
    "    t2, p2, _ = B\n",
    "    return (t1 <= t2 and p1 >= p2) and (t1 < t2 or p1 > p2)\n",
    "\n",
    "\n",
    "def pareto_rank(objs):\n",
    "    n = len(objs)\n",
    "    dom_counts = [0] * n\n",
    "    dominated_by = [[] for _ in range(n)]\n",
    "    fronts = [[]]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if dominates(objs[i], objs[j]):\n",
    "                dominated_by[i].append(j)\n",
    "            elif dominates(objs[j], objs[i]):\n",
    "                dom_counts[i] += 1\n",
    "        if dom_counts[i] == 0:\n",
    "            fronts[0].append(i)\n",
    "\n",
    "    k = 0\n",
    "    while fronts[k]:\n",
    "        nxt = []\n",
    "        for i in fronts[k]:\n",
    "            for j in dominated_by[i]:\n",
    "                dom_counts[j] -= 1\n",
    "                if dom_counts[j] == 0:\n",
    "                    nxt.append(j)\n",
    "        k += 1\n",
    "        fronts.append(nxt)\n",
    "\n",
    "    return fronts[:-1]\n",
    "\n",
    "def crowding_distance(front_indices, objs):\n",
    "    \"\"\"\n",
    "    front_indices: list of indices (into objs) belonging to one Pareto front\n",
    "    objs: list of (time, profit, weight)\n",
    "\n",
    "    Returns: dict {idx: distance}\n",
    "    \"\"\"\n",
    "    if not front_indices:\n",
    "        return {}\n",
    "\n",
    "    # init distances\n",
    "    dist = {i: 0.0 for i in front_indices}\n",
    "\n",
    "    # use only time (index 0, minimise) and profit (index 1, maximise)\n",
    "    num_obj = 2\n",
    "    for m in range(num_obj):\n",
    "        vals = [(i, objs[i][m]) for i in front_indices]\n",
    "\n",
    "        if m == 0:\n",
    "            # time: smaller is better â†’ sort ascending\n",
    "            vals.sort(key=lambda x: x[1])\n",
    "        else:\n",
    "            # profit: larger is better â†’ sort descending\n",
    "            vals.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        v_min = vals[0][1]\n",
    "        v_max = vals[-1][1]\n",
    "        if v_max == v_min:\n",
    "            # no spread on this dimension\n",
    "            continue\n",
    "\n",
    "        # boundary points get infinite crowding\n",
    "        dist[vals[0][0]]  = float(\"inf\")\n",
    "        dist[vals[-1][0]] = float(\"inf\")\n",
    "\n",
    "        # internal points\n",
    "        for k in range(1, len(vals) - 1):\n",
    "            i_prev, v_prev = vals[k - 1]\n",
    "            i_curr, v_curr = vals[k]\n",
    "            i_next, v_next = vals[k + 1]\n",
    "            incr = (v_next - v_prev) / (v_max - v_min)\n",
    "            dist[i_curr] += incr\n",
    "\n",
    "    return dist\n",
    "\n",
    "# ===============================================================\n",
    "# DIVERSITY-AWARE MATING SCORES + TOURNAMENT SELECTION\n",
    "# ===============================================================\n",
    "def compute_mating_scores(objs,\n",
    "                          alpha=0.5,  # Pareto rank weight\n",
    "                          beta=0.3,   # crowding weight\n",
    "                          gamma=0.2   # sparsity weight\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    objs: list of (T, P, W)\n",
    "    Returns: list[float] score per individual, higher = more likely to mate.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(objs)\n",
    "    if n == 0:\n",
    "        return []\n",
    "\n",
    "    # ---------- 1) Pareto rank score (front 0 best) ----------\n",
    "    fronts = pareto_rank(objs)  # list of fronts, each is list of indices\n",
    "    rank_score = [0.0] * n\n",
    "    if len(fronts) == 1:\n",
    "        # everyone same front\n",
    "        for i in fronts[0]:\n",
    "            rank_score[i] = 1.0\n",
    "    else:\n",
    "        max_front = max(1, len(fronts) - 1)\n",
    "        for rank, front in enumerate(fronts):\n",
    "            val = 1.0 - (rank / max_front)   # front 0 â†’ 1.0, last front â†’ ~0.0\n",
    "            for i in front:\n",
    "                rank_score[i] = val\n",
    "\n",
    "    # ---------- 2) Crowding score over whole pop ----------\n",
    "    idxs = list(range(n))\n",
    "    cd = crowding_distance(idxs, objs)  # dict {idx: dist}\n",
    "    cd_vec = [cd.get(i, 0.0) for i in range(n)]\n",
    "\n",
    "    # normalise crowding, keep boundary INF higher than others\n",
    "    finite_vals = [v for v in cd_vec if math.isfinite(v)]\n",
    "    if not finite_vals:\n",
    "        cd_norm = [0.0] * n\n",
    "    else:\n",
    "        max_fin = max(finite_vals)\n",
    "        if max_fin <= 0.0:\n",
    "            cd_norm = [0.0] * n\n",
    "        else:\n",
    "            cd_norm = []\n",
    "            for v in cd_vec:\n",
    "                if not math.isfinite(v):\n",
    "                    cd_norm.append(1.1)  # slightly above max finite\n",
    "                else:\n",
    "                    cd_norm.append(v / max_fin)\n",
    "\n",
    "    # ---------- 3) Sparsity: distance from centroid in (T,P) ----------\n",
    "    times = np.array([o[0] for o in objs], dtype=float)\n",
    "    profits = np.array([o[1] for o in objs], dtype=float)\n",
    "\n",
    "    t_bar = float(times.mean())\n",
    "    p_bar = float(profits.mean())\n",
    "\n",
    "    div_radius = np.sqrt((times - t_bar) ** 2 + (profits - p_bar) ** 2)\n",
    "    max_r = float(div_radius.max()) if n > 0 else 0.0\n",
    "    if max_r <= 0.0:\n",
    "        div_norm = [0.0] * n\n",
    "    else:\n",
    "        div_norm = [float(r / max_r) for r in div_radius]\n",
    "\n",
    "    # ---------- 4) Combine into final score ----------\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        s = (alpha * rank_score[i] +\n",
    "             beta  * cd_norm[i] +\n",
    "             gamma * div_norm[i])\n",
    "        scores.append(s)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def tournament_select(pop, scores, k=TOURN_K):\n",
    "    \"\"\"\n",
    "    k-way tournament on 'scores', returns *one individual* from pop.\n",
    "    Higher score = more likely to win.\n",
    "    \"\"\"\n",
    "    n = len(pop)\n",
    "    if n == 0:\n",
    "        raise ValueError(\"tournament_select called with empty population\")\n",
    "    k = min(k, n)\n",
    "\n",
    "    cand = random.sample(range(n), k)\n",
    "    best_idx = max(cand, key=lambda i: scores[i])\n",
    "    return pop[best_idx]\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# EVOLUTION LOOP (with 2+2 tail elites per generation)\n",
    "# ===============================================================\n",
    "def run_evo(inst, order, dists, recs, total_dist,\n",
    "            gens=GENERATIONS, pop_size=POP_SIZE):\n",
    "\n",
    "    global archive_pop, archive_objs, bestP, bestP_sol, bestT, bestT_sol\n",
    "\n",
    "\n",
    "    # initial population\n",
    "    pop = [build_seed(inst, order, dists, recs, total_dist)\n",
    "           for _ in range(pop_size)]\n",
    "    objs = [evaluate(inst, order, dists, recs, c) for c in pop]\n",
    "\n",
    "    for g in range(gens):\n",
    "        # update global best profit & best time from current population\n",
    "        for sol, (T, P, W) in zip(pop, objs):\n",
    "            if P > bestP:\n",
    "                bestP = P\n",
    "                bestP_sol = sol[:]\n",
    "            if bestT is None or T < bestT:\n",
    "                bestT = T\n",
    "                bestT_sol = sol[:]\n",
    "\n",
    "        print(f\"[GEN {g:4d}] min_time={min(o[0] for o in objs):.1f}  max_profit={max(o[1] for o in objs):.0f}\")\n",
    "\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 1) IDENTIFY ELITES FROM CURRENT POPULATION\n",
    "        #    - 2 fastest (smallest time)\n",
    "        #    - 2 richest (largest profit)\n",
    "        # -------------------------------------------------------\n",
    "        num_tail_elites = 2\n",
    "\n",
    "        # indices sorted by time (ascending: fastest first)\n",
    "        idx_by_time = sorted(range(len(objs)), key=lambda i: objs[i][0])\n",
    "        # indices sorted by profit (descending: richest first)\n",
    "        idx_by_profit = sorted(range(len(objs)), key=lambda i: objs[i][1], reverse=True)\n",
    "\n",
    "        elite_indices = []\n",
    "\n",
    "        # take 2 fastest\n",
    "        for i in idx_by_time[:num_tail_elites]:\n",
    "            if i not in elite_indices:\n",
    "                elite_indices.append(i)\n",
    "\n",
    "        # take 2 richest\n",
    "        for i in idx_by_profit[:num_tail_elites]:\n",
    "            if i not in elite_indices:\n",
    "                elite_indices.append(i)\n",
    "\n",
    "        elite_solutions = [pop[i][:] for i in elite_indices]\n",
    "        elite_objs      = [objs[i]   for i in elite_indices]\n",
    "\n",
    "        # ==========================\n",
    "        # PARALLEL HILL-CLIMB ELITES\n",
    "        # ==========================\n",
    "\n",
    "        for e in range(len(elite_solutions)):\n",
    "            sol = elite_solutions[e][:]\n",
    "            best_T, best_P, best_W = elite_objs[e]\n",
    "\n",
    "            for _ in range(HC_STEPS):\n",
    "                j = random.randrange(len(sol))\n",
    "\n",
    "                new = sol[:]               # work on a copy\n",
    "                new[j] = not new[j]        # flip one item\n",
    "                new = repair_to_capacity(new, recs, inst[\"capacity\"])\n",
    "                T2,P2,W2 = evaluate(inst,order,dists,recs,new)\n",
    "\n",
    "                # accept only capacity-safe improvements\n",
    "                if (T2 < best_T and P2 >= best_P*0.95) or (P2 > best_P and T2 <= best_T*1.05):\n",
    "                    sol = new[:]           # commit full improved candidate\n",
    "                    best_T,best_P,best_W = T2,P2,W2\n",
    "\n",
    "            elite_solutions[e] = sol\n",
    "            elite_objs[e]      = (best_T,best_P,best_W)\n",
    "\n",
    "\n",
    "        # ==========================\n",
    "        # 2-OPT TOUR HILLCLIMB FOR ELITES\n",
    "        # ==========================\n",
    "\n",
    "        for e in range(len(elite_solutions)):\n",
    "            sol = elite_solutions[e]\n",
    "            best_T, best_P, best_W = elite_objs[e]\n",
    "\n",
    "            # local independent tour\n",
    "            tour = order[:]\n",
    "\n",
    "            for _ in range(TOUR_2OPT_STEPS):\n",
    "                n = len(tour)\n",
    "                i = random.randrange(0, n-3)\n",
    "                j = random.randrange(i+2, n)\n",
    "\n",
    "                if j <= i+1:\n",
    "                    continue\n",
    "\n",
    "                new_tour = tour[:]                 # local copy\n",
    "                new_tour[i:j] = new_tour[i:j][::-1]\n",
    "\n",
    "\n",
    "                new_sol = repair_to_capacity(sol[:], recs, inst[\"capacity\"])\n",
    "                T2,P2,W2 = evaluate(inst,new_tour,compute_dists(new_tour,inst[\"coords\"]),recs,new_sol)\n",
    "\n",
    "                if (T2 < best_T and P2 >= best_P*0.95) or (P2 > best_P and T2 <= best_T*1.05):\n",
    "                    tour = new_tour[:]             # commit tour\n",
    "                    sol  = new_sol[:]              # commit items\n",
    "                    best_T,best_P,best_W = T2,P2,W2\n",
    "\n",
    "            elite_solutions[e] = sol\n",
    "            elite_objs[e]      = (best_T,best_P,best_W)\n",
    "\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # ðŸ’¥ Inject fresh greedy individuals into population\n",
    "        #     - maintains exploration\n",
    "        #     - prevents collapse into GEN0 stagnation\n",
    "        # -------------------------------------------------------\n",
    "        fresh = []\n",
    "\n",
    "\n",
    "        for _ in range(NUM_GREEDIES):\n",
    "            seed = build_seed(inst, order, dists, recs, total_dist)\n",
    "            fresh.append(seed)\n",
    "\n",
    "        fresh_objs = [evaluate(inst, order, dists, recs, s) for s in fresh]\n",
    "\n",
    "        # add to population pre-selection\n",
    "        pop  += fresh\n",
    "        objs += fresh_objs\n",
    "\n",
    "\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 2) DIVERSITY-AWARE OFFSPRING GENERATION\n",
    "        #     - parents chosen by combined (rank + crowding + sparsity) score\n",
    "        # -------------------------------------------------------\n",
    "        # scores correspond to *current* population objs\n",
    "        mating_scores = compute_mating_scores(objs)\n",
    "\n",
    "        offspring = []\n",
    "        while len(offspring) < pop_size:\n",
    "            # parents selected via tournament on scores\n",
    "            parent_a = tournament_select(pop, mating_scores, k=TOURN_K)\n",
    "            parent_b = tournament_select(pop, mating_scores, k=TOURN_K)\n",
    "\n",
    "            # avoid identical parents if possible\n",
    "            if parent_a is parent_b and len(pop) > 1:\n",
    "                parent_b = tournament_select(pop, mating_scores, k=TOURN_K)\n",
    "\n",
    "            child = crossover(parent_a, parent_b)\n",
    "            child = mutate(child)\n",
    "\n",
    "            child = repair_to_capacity(child, recs, inst[\"capacity\"])\n",
    "            _, _, W = evaluate(inst, order, dists, recs, child)\n",
    "            cap = inst[\"capacity\"]\n",
    "            min_fill = 0.30 + 0.40 * (g / gens)   # starts at 30% â†’ rises to 70% by last gen\n",
    "            target_weight = cap * min_fill\n",
    "\n",
    "            if W < target_weight:\n",
    "                child = light_mutate(child)\n",
    "                child = repair_to_capacity(child, recs, inst[\"capacity\"])\n",
    "\n",
    "            offspring.append(child)\n",
    "\n",
    "        off_objs = [evaluate(inst, order, dists, recs, c) for c in offspring]\n",
    "\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 3) NSGA-II ENVIRONMENTAL SELECTION ON POP âˆª OFFSPRING\n",
    "        # -------------------------------------------------------\n",
    "        combined = pop + offspring\n",
    "        comb_objs = objs + off_objs\n",
    "\n",
    "        fronts = pareto_rank(comb_objs)\n",
    "\n",
    "        new_pop = []\n",
    "        new_objs = []\n",
    "\n",
    "        for front in fronts:\n",
    "            if len(new_pop) + len(front) <= pop_size:\n",
    "                for idx in front:\n",
    "                    new_pop.append(combined[idx])\n",
    "                    new_objs.append(comb_objs[idx])\n",
    "            else:\n",
    "                need = pop_size - len(new_pop)\n",
    "                picks = random.sample(front, need)\n",
    "                for idx in picks:\n",
    "                    new_pop.append(combined[idx])\n",
    "                    new_objs.append(comb_objs[idx])\n",
    "                break\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 4) RE-INSERT ELITES INTO POPULATION\n",
    "        #    (replace worst individuals if missing)\n",
    "        # -------------------------------------------------------\n",
    "        # define \"worst\" as: largest time, then lowest profit\n",
    "        def worst_index(objs_list):\n",
    "            return max(range(len(objs_list)),\n",
    "                       key=lambda i: (objs_list[i][0], -objs_list[i][1]))\n",
    "\n",
    "        # for each elite, if not already present, inject it\n",
    "        for e_sol, e_obj in zip(elite_solutions, elite_objs):\n",
    "            # simple membership check by objective tuple\n",
    "            if e_obj not in new_objs:\n",
    "                wi = worst_index(new_objs)\n",
    "                new_pop[wi] = e_sol[:]\n",
    "                new_objs[wi] = e_obj\n",
    "\n",
    "        pop, objs = new_pop, new_objs\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 4.5) ENSURE GLOBAL ELITES ARE PRESENT IN POP\n",
    "        # -------------------------------------------------------\n",
    "        # replace worst-for-that-objective if global elite is missing\n",
    "\n",
    "        # helper: worst by profit (lowest profit)\n",
    "        def worst_by_profit(objs_list):\n",
    "            return min(range(len(objs_list)), key=lambda i: objs_list[i][1])\n",
    "\n",
    "        # helper: worst by time (largest time)\n",
    "        def worst_by_time(objs_list):\n",
    "            return max(range(len(objs_list)), key=lambda i: objs_list[i][0])\n",
    "\n",
    "        # profit-elite\n",
    "        if bestP_sol is not None:\n",
    "            Tp, Pp, Wp = evaluate(inst, order, dists, recs, bestP_sol)\n",
    "            eliteP_obj = (Tp, Pp, Wp)\n",
    "            if eliteP_obj not in objs:\n",
    "                wi = worst_by_profit(objs)\n",
    "                pop[wi] = bestP_sol[:]\n",
    "                objs[wi] = eliteP_obj\n",
    "\n",
    "        # time-elite\n",
    "        if bestT_sol is not None:\n",
    "            Tt, Pt, Wt = evaluate(inst, order, dists, recs, bestT_sol)\n",
    "            eliteT_obj = (Tt, Pt, Wt)\n",
    "            if eliteT_obj not in objs:\n",
    "                wi = worst_by_time(objs)\n",
    "                pop[wi] = bestT_sol[:]\n",
    "                objs[wi] = eliteT_obj\n",
    "\n",
    "\n",
    "        # =====================================================\n",
    "        # 5) UPDATE PERSISTENT ND ARCHIVE (now stores GEN)\n",
    "        # =====================================================\n",
    "        # Extend previous archive with current generation results\n",
    "        # old archive_objs = [(T,P,W,gen), ...]\n",
    "        # objs = [(T,P,W), ...] â†’ must convert to include this gen\n",
    "\n",
    "        # Convert current objs to 4-tuples with generation tag\n",
    "        objs_with_gen = [(T,P,W,g) for (T,P,W) in objs]\n",
    "\n",
    "        combo_objs = archive_objs + objs_with_gen\n",
    "\n",
    "        # find global ND set over all time\n",
    "        fronts = pareto_rank([(t,p,w) for (t,p,w,_) in combo_objs])\n",
    "        nd = fronts[0]  # keep indices of ND only\n",
    "\n",
    "        # Build new archive lists\n",
    "        newA_pop  = []\n",
    "        newA_objs = []\n",
    "\n",
    "        for i in nd:\n",
    "            if i < len(archive_objs):        # came from previous archive\n",
    "                newA_pop.append(archive_pop[i])\n",
    "                newA_objs.append(archive_objs[i])   # already contains gen\n",
    "            else:                             # came from *this generation*\n",
    "                j = i - len(archive_objs)\n",
    "                newA_pop.append(pop[j])\n",
    "                newA_objs.append(objs_with_gen[j])\n",
    "\n",
    "        # remove duplicates based on (rounded T,P) â†’ keep lower W or earlier GEN doesn't matter yet\n",
    "        uniq = {}\n",
    "        for sol, obj in zip(newA_pop,newA_objs):\n",
    "            T,P,W,GEN = obj\n",
    "            key = (round(T,3), round(P,1))\n",
    "            if key not in uniq or W < uniq[key][1][2]:\n",
    "                uniq[key] = (sol, obj)\n",
    "\n",
    "        archive_pop  = [v[0] for v in uniq.values()]\n",
    "        archive_objs = [v[1] for v in uniq.values()]   # now contains T,P,W,GEN tuples\n",
    "\n",
    "        # enforce MAX_ARCHIVE cap using crowding\n",
    "#        if len(archive_objs) > MAX_ARCHIVE:\n",
    "#            idxs = range(len(archive_objs))\n",
    "#            cd = crowding_distance(idxs, [(t,p,w) for (t,p,w,_) in archive_objs])\n",
    "#            keep = sorted(idxs, key=lambda k: cd.get(k,0), reverse=True)[:MAX_ARCHIVE]\n",
    "#            archive_pop  = [archive_pop[k]  for k in keep]\n",
    "#            archive_objs = [archive_objs[k] for k in keep]\n",
    "\n",
    "   \n",
    "    return pop, objs\n",
    "\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# HYPERVOLUME\n",
    "# ===============================================================\n",
    "\n",
    "def compute_hypervolume(objs, ideal, nadir):\n",
    "    \"\"\"\n",
    "    objs may be 3-tuple (T,P,W) or 4-tuple (T,P,W,GEN)\n",
    "    Hypervolume clipped so solutions outside NADIR contribute nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    pts = []\n",
    "    for x in objs:\n",
    "        # Accept either length-3 or length-4 tuples\n",
    "        if len(x) == 3:\n",
    "            T,P,W = x\n",
    "        else:\n",
    "            T,P,W,G = x  # GEN ignored for HV\n",
    "        pts.append((T, -P))\n",
    "\n",
    "    # clip: only keep pts with T <= NadirT and profit >= -IdealP\n",
    "    clipped = [(T,p) for (T,p) in pts if (T <= nadir[0] and p >= ideal[1])]\n",
    "\n",
    "    if not clipped:\n",
    "        return 0.0\n",
    "\n",
    "    clipped.sort(key=lambda x: x[0])  # sort by time asc\n",
    "    hv = 0.0\n",
    "    prev_t = ideal[0]\n",
    "\n",
    "    for (t,p) in clipped:\n",
    "        width  = max(0, t - prev_t)\n",
    "        height = max(0, nadir[1] - p)\n",
    "        hv += width * height\n",
    "        prev_t = t\n",
    "\n",
    "    width  = max(0, nadir[0] - prev_t)\n",
    "    height = max(0, nadir[1] - clipped[-1][1])\n",
    "    hv += width * height\n",
    "\n",
    "    return hv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# RUN EVERYTHING\n",
    "# ===============================================================\n",
    "print(\"[INFO] Loading TTP instanceâ€¦\")\n",
    "inst = parse_ttp(INSTANCE_PATH)\n",
    "\n",
    "print(\"[INFO] Building NN tourâ€¦\")\n",
    "order = nn_tour(inst[\"coords\"])\n",
    "dists = compute_dists(order, inst[\"coords\"])\n",
    "print(f\"[TSP] NN length = {dists.sum():.0f}\")\n",
    "\n",
    "cand_lists = build_candidate_lists(inst[\"coords\"], k=CAND_K)\n",
    "if cand_lists is not None:\n",
    "    print(\"[INFO] Running 2-opt with candidate listsâ€¦\")\n",
    "    order = two_opt_with_candidates(order, inst[\"coords\"], cand_lists, max_passes=TWO_OPT_PASSES)\n",
    "    dists = compute_dists(order, inst[\"coords\"])\n",
    "    print(f\"[TSP] Improved length = {dists.sum():.0f}\")\n",
    "else:\n",
    "    print(\"[INFO] Skipping 2-opt improvement.\")\n",
    "\n",
    "print(\"[INFO] Preprocessing itemsâ€¦\")\n",
    "recs, total_dist = prep_items(inst, order, dists)\n",
    "\n",
    "pop, objs = run_evo(inst, order, dists, recs, total_dist,\n",
    "                    gens=GENERATIONS, pop_size=POP_SIZE)\n",
    "\n",
    "def select_top20_from_archive(archive_objs, archive_pop, target=MAX_ARCHIVE):\n",
    "    \"\"\"\n",
    "    Îµ-dominance thinning but guaranteed to return EXACTLY `target` points.\n",
    "    Starts coarse (spread) -> refines -> fills missing slots by nearest-neighbour expansion.\n",
    "    Legal competition method: no NADIR, no external bounds.\n",
    "    \"\"\"\n",
    "\n",
    "    objs = archive_objs[:]  # (T,P,W,GEN)\n",
    "    pop  = archive_pop[:]\n",
    "\n",
    "    # normalise using internal archive only\n",
    "    T = np.array([o[0] for o in objs])\n",
    "    P = np.array([o[1] for o in objs])\n",
    "    Tmin, Tmax = T.min(), T.max()\n",
    "    Pmin, Pmax = P.min(), P.max()\n",
    "\n",
    "    norm = np.column_stack(((T-Tmin)/(Tmax-Tmin+1e-12),\n",
    "                            (P-Pmin)/(Pmax-Pmin+1e-12)))\n",
    "\n",
    "    eps = 0.30  # start wide spread\n",
    "    survivors = set()\n",
    "\n",
    "    while eps > 1e-4 and len(survivors) < target:\n",
    "        buckets = {}\n",
    "        for i,(x,y) in enumerate(norm):\n",
    "            key = (int(x/eps), int(y/eps))\n",
    "            if key not in buckets:       # keep only first in cell\n",
    "                buckets[key] = i\n",
    "\n",
    "        survivors = set(buckets.values())\n",
    "\n",
    "        # shrink only if too few\n",
    "        if len(survivors) < target:\n",
    "            eps *= 0.75   # refine grid granularity\n",
    "\n",
    "    survivors = list(survivors)\n",
    "\n",
    "    # If too many, trim to nearest-spread 20 (crowding-distance style)\n",
    "    if len(survivors) > target:\n",
    "        pts = norm[survivors]\n",
    "        dmat = np.sqrt(((pts[:,None,:] - pts[None,:,:])**2).sum(2)) + np.eye(len(pts))*1e9\n",
    "        crowd = dmat.min(1)  # large min-dist = sparse = valuable\n",
    "        survivors = [survivors[i] for i in np.argsort(-crowd)[:target]]\n",
    "\n",
    "    # If still fewer than target, fill from remaining nearest to sparse set\n",
    "    if len(survivors) < target:\n",
    "        remaining = list(set(range(len(objs))) - set(survivors))\n",
    "        pts_keep = norm[survivors]\n",
    "        fill = []\n",
    "        for i in remaining:\n",
    "            d = np.sqrt(((pts_keep - norm[i])**2).sum(1)).min()\n",
    "            fill.append((d,i))\n",
    "        fill = sorted(fill, reverse=True)  # pick points that expand boundary most\n",
    "        survivors += [idx for (_,idx) in fill[:target-len(survivors)]]\n",
    "\n",
    "    survivors = survivors[:target]\n",
    "    return [pop[i] for i in survivors], [objs[i] for i in survivors]\n",
    "\n",
    "\n",
    "# ========= SELECT FINAL 20 =========\n",
    "final_pop, final_objs = select_top20_from_archive(archive_objs, archive_pop, target=MAX_ARCHIVE)\n",
    "\n",
    "print(\"\\n=== FINAL SUBMISSION SET (20) ===\")\n",
    "for (T,P,W,G) in sorted(final_objs, key=lambda x: x[0]):\n",
    "    print(f\"time={T:.1f}  profit={P:.0f}  weight={W:.0f}  GEN={G}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== FINAL PARETO FRONT ===\")\n",
    "paired = sorted(zip(pop, objs), key=lambda x: x[1][0])\n",
    "for _, (T, P, W) in paired:\n",
    "    print(f\"time={T:.1f}  profit={P:.0f}  weight={W:.0f}\") \n",
    "\n",
    "# ===================== HYPERVOLUME OUTPUT =====================\n",
    "# Ideal & nadir from your earlier results\n",
    "hv_raw = compute_hypervolume(objs, IDEAL, NADIR)\n",
    "\n",
    "# normalised HV in [0,1]^2\n",
    "range_t = NADIR[0] - IDEAL[0]\n",
    "range_p = -IDEAL[1]\n",
    "hv_norm = hv_raw / (range_t * range_p)\n",
    "\n",
    "print(\"\\n=== HYPERVOLUME ===\")\n",
    "print(f\"Raw HV   : {hv_raw:.6e}\")\n",
    "print(f\"Norm HV  : {hv_norm:.6f}\")\n",
    "\n",
    "print(\"\\n=== ARCHIVE SUMMARY =======================\")\n",
    "print(f\"ND archive size: {len(archive_objs)}\")\n",
    "for (T,P,W,G) in sorted(archive_objs, key=lambda x:x[0]):\n",
    "    print(f\"time={T:.1f}  profit={P:.0f}  weight={W:.0f}  GEN={G}\")\n",
    "\n",
    "\n",
    "# HV on archive \n",
    "hv_raw_nd = compute_hypervolume(archive_objs, IDEAL, NADIR)\n",
    "hv_norm_nd = hv_raw_nd / (range_t * range_p)\n",
    "\n",
    "print(\"\\n=== GLOBAL HYPERVOLUME (ARCHIVE) ===\")\n",
    "print(f\"Raw HV   : {hv_raw_nd:.6e}\")\n",
    "print(f\"Norm HV  : {hv_norm_nd:.6f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df45f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ================== USE SUBMISSION SET ==================\n",
    "# not archive_objs â€” only final 20 exported points\n",
    "pts = np.array([(t,p,g) for (t,p,w,g) in final_objs])\n",
    "pts = pts[pts[:,0].argsort()]  # sort by time\n",
    "\n",
    "times   = pts[:,0]\n",
    "profits = pts[:,1]\n",
    "\n",
    "T_min, T_max = IDEAL[0], NADIR[0]\n",
    "P_min, P_max = 0, 42_036.0\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "# -------------------------------------------------\n",
    "#  Dominated area shading for the displayed 20 only\n",
    "# -------------------------------------------------\n",
    "for i in range(len(times)):\n",
    "    xs = [times[i], T_max, T_max, times[i]]\n",
    "    ys = [P_min, P_min, profits[i], profits[i]]\n",
    "    plt.fill(xs, ys, color=\"lightblue\", alpha=0.15)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Hypervolume boundary (step front)\n",
    "# -------------------------------------------------\n",
    "hv_x = [T_min]\n",
    "hv_y = [P_min]\n",
    "\n",
    "for t,p in zip(times, profits):\n",
    "    hv_x += [t, t]\n",
    "    hv_y += [hv_y[-1], p]\n",
    "\n",
    "hv_x.append(T_max)\n",
    "hv_y.append(hv_y[-1])\n",
    "\n",
    "plt.plot(hv_x, hv_y, color=\"pink\", linewidth=2.3,\n",
    "         label=\"HV step boundary (100-set)\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Pareto front scatter\n",
    "# -------------------------------------------------\n",
    "plt.plot(times, profits, \"-o\", color=\"blue\", markersize=6,\n",
    "         markeredgecolor=\"black\", label=\"Selected 100\")\n",
    "\n",
    "# Best markers\n",
    "best_t = np.argmin(times)\n",
    "best_p = np.argmax(profits)\n",
    "\n",
    "plt.scatter(times[best_t], profits[best_t], s=140,\n",
    "            color=\"red\", edgecolor=\"black\", label=\"Fastest\")\n",
    "plt.scatter(times[best_p], profits[best_p], s=140,\n",
    "            color=\"green\", edgecolor=\"black\", label=\"Most profitable\")\n",
    "\n",
    "plt.xlim(T_min, T_max)\n",
    "plt.ylim(P_min, P_max)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlabel(\"Time (lower better)\")\n",
    "plt.ylabel(\"Profit (higher better)\")\n",
    "plt.title(f\"Top-100 Pareto Submission Set a289_n279 â€” Norm HV  : {hv_norm_nd:.6f}\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3eb23-f30a-499d-be64-4a9adc76eb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
